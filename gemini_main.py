import asyncio
import os
import json
from datetime import datetime
from google import genai
from google.genai import types
from typing import Literal, List, Optional
from typing_extensions import TypedDict
from dotenv import load_dotenv
from mcp_connector import get_kipris_connector

# --- Configuration ---
USE_JSON_OUTPUT = True  # Set to True to enable JSON structured output
# ---------------------

class GeminiDebugLogger:
    def __init__(self):
        self.steps = []
        self.gemini_api_call_count = 0
        self.kipris_api_call_count = 0
        self.start_time = datetime.now()
        self.total_tokens = None

    def log_api_call(self, role, content=None, function_calls=None):
        if role == "model":
            self.gemini_api_call_count += 1
        
        entry = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "function_calls": function_calls,
            "turn": self.gemini_api_call_count if role == "model" else 0
        }
        self.steps.append(entry)

    def log_tool_result(self, tool_name, result):
        self.kipris_api_call_count += 1
        self.steps.append({
            "role": "tool",
            "tool_name": tool_name,
            "result": result,
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "turn": self.gemini_api_call_count
        })

    def set_usage(self, usage):
        self.total_tokens = usage

    def generate_report(self):
        report = [
            "# Gemini API Flow Debug Log",
            f"- **Date**: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"- **Total Gemini API Calls**: {self.gemini_api_call_count}",
        ]
        
        if self.total_tokens:
            report.append(f"- **Token Usage**: Prompt: {self.total_tokens.prompt_token_count}, Candidates: {self.total_tokens.candidates_token_count}, Total: {self.total_tokens.total_token_count}")
        
        report.append("\n## ğŸ’¬ Communication Flow\n")
        
        for step in self.steps:
            role = step['role']
            time = step['timestamp']
            
            if role == "user":
                report.append(f"### ğŸ‘¤ User (Input) *[{time}]*")
                report.append(f"```text\n{step['content']}\n```\n")
            
            elif role == "model":
                turn_label = f" (Turn {step['turn']})" if step['turn'] > 0 else ""
                report.append(f"### ğŸ¤– Gemini Response{turn_label} *[{time}]*")
                
                # Show text part if exists
                if step['content']:
                    report.append(f"**Thought/Draft**:\n\n{step['content']}\n")
                
                # Show function calls if exists
                if step['function_calls']:
                    report.append("#### ğŸ› ï¸ Tool Usage (Function Calls)")
                    for fc in step['function_calls']:
                        args_json = json.dumps(fc.args, indent=2, ensure_ascii=False)
                        report.append(f"- **Tool**: `{fc.name}`")
                        report.append(f"- **Arguments**:\n```json\n  {args_json}\n```")
                report.append("---")

            elif role == "tool":
                report.append(f"### ğŸ“¥ Tool Result (`{step['tool_name']}`) *[{time}]*")
                # Truncate very long tool results for readability
                res_str = str(step['result'])
                if len(res_str) > 2000:
                    res_str = res_str[:2000] + "... (truncated)"
                report.append(f"```json\n{res_str}\n```\n")

        return "\n".join(report)

    def save(self, folder="debug"):
        if not os.path.exists(folder):
            os.makedirs(folder)
        
        filename = f"api_flow_{self.start_time.strftime('%Y%m%d_%H%M%S')}.md"
        path = os.path.join(folder, filename)
        
        with open(path, "w", encoding="utf-8") as f:
            f.write(self.generate_report())
        
        return path

# PROMPT_1 with patent grounding instructions
PROMPT_1 = """
1. ë‹¹ì‹ ì€ ê´‘ê³  ì‹ ë¢°ì„± ë¶„ì„ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìë¡œë¶€í„° ë°›ì€ ê´‘ê³ ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ê´‘ê³ ì™€ ì œí’ˆì˜ ì‹ ë¢°ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ìœ íŠœë¸Œ ì‡¼ì¸ ì—ì„œ ì‹œì²­í•œ ê´‘ê³ ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. í‰ê°€í•œ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

2. ê´‘ê³  ì‹ ë¢°ì„± ë¶„ì„ì„ í†µí•´ ê´‘ê³ ê°€ ê³¼ì¥ë˜ì—ˆëŠ”ì§€, ì‚¬ì‹¤ì— ê¸°ë°˜í–ˆëŠ”ì§€, ë˜ëŠ” ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. 
ê´‘ê³ ì—ì„œ ì œí’ˆì— ëŒ€í•œ íŠ¹í—ˆë¥¼ ì–¸ê¸‰í•˜ëŠ” ë¶€ë¶„ì´ ìˆë‹¤ë©´, ì œê³µëœ 'patent_search' ë˜ëŠ” 'patent_keyword_search' ë“± KIPRIS ê´€ë ¨ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ íŠ¹í—ˆê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”. 
ë˜í•œ ì¼ë°˜ì ì¸ ì •ë³´ í™•ì¸ì„ ìœ„í•´ "Google ê²€ìƒ‰ ê·¸ë¼ìš´ë”©"ë„ í•¨ê»˜ í™œìš©í•˜ì„¸ìš”.

3. ë‹µë³€ì€ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.

4. ë‹µë³€ì€ ì „ë¬¸ì ì´ê³  ê°„ê²°í•œ ì–´ì¡°ë¡œ ì„¤ëª…í•˜ì„¸ìš”. ë‹µë³€ì€ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤. ì˜¨í™”í•œ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.

5. ì‚¬ìš©ìëŠ” ë””ì§€í„¸ ì •ë³´ì— ì·¨ì•½í•œ ê³ ë ¹ì, ë˜ëŠ” ê´‘ê³ ì— ì‰½ê²Œ í˜„í˜¹ë˜ëŠ” ì¼ë°˜ ì†Œë¹„ì, ë˜ëŠ” ì²­ì†Œë…„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.

6. ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë‹µë³€ í˜•ì‹ì„ ì œê³µí•˜ì„¸ìš”.
 - ê´‘ê³ ì˜ ì‹ ë¢°ì„±ì„ ë²”ì£¼í™”í•˜ì—¬ ì œì‹œí•˜ì„¸ìš”(ìœ„í—˜, ì•ˆì „, ì£¼ì˜).
 - ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì˜ ë¬¸ì œì ì„ ê°„ëµí™”í•´ì„œ ì œì‹œí•˜ì„¸ìš”.
 - ***ê´‘ê³ ì—ì„œ íŠ¹í—ˆì— ëŒ€í•œ ì–¸ê¸‰ì´ ìˆì„ ë•Œì—ë§Œ*** KIPRIS ë„êµ¬ë¥¼ í†µí•´ í™•ì¸í•œ íŠ¹í—ˆ ì •ë³´(ì¡´ì¬ ì—¬ë¶€, íŠ¹í—ˆ ë²ˆí˜¸, ì¶œì›ì¸ ë“±)ë¥¼ ìƒì„¸íˆ ì œì‹œí•˜ì„¸ìš”.
 - ê²€ìƒ‰ ê·¸ë¼ìš´ë”©ìœ¼ë¡œ í™•ì¸í•œ ì •ë³´ëŠ” ì¶œì²˜ì™€ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”(ë§í¬ í¬í•¨).

7. ì´í›„ ë‚´ìš©ì€ ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
"""

PROMPT_2 = """
# Role: ê´‘ê³  ì‹ ë¢°ì„± ë° ê³¼í•™ì  íƒ€ë‹¹ì„± ë¶„ì„ ì „ë¬¸ê°€

## 1. ë¶„ì„ ë¯¸ì…˜
ì‚¬ìš©ìê°€ ì œê³µí•œ ìœ íŠœë¸Œ ì‡¼ì¸  ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì œí’ˆì˜ ì‹ ë¢°ì„±ì„ [ìœ„í—˜], [ì£¼ì˜], [ì•ˆì „]ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ì˜í•™ì /ê¸°ìˆ ì  í—ˆìœ„ ì‚¬ì‹¤ì„ ê²€ì¦í•©ë‹ˆë‹¤. íŠ¹íˆ ë””ì§€í„¸ ì •ë³´ì— ì·¨ì•½í•œ ê³ ë ¹ìë‚˜ ì²­ì†Œë…„ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¹œì ˆí•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.

## 2. í•µì‹¬ ê²€ì¦ ë¡œì§ (ê²€ìƒ‰ ì „ëµ)
ê²€ìƒ‰ ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ 'ê²°ê³¼ ì—†ìŒ' ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ì„¸ìš”.

### STEP 1: í‚¤ì›Œë“œ ë‹¤ë³€í™” (KIPRIS ë° Google ê²€ìƒ‰ ì‹œ ì ìš©)
- **ì œí’ˆëª… ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ:** ê´‘ê³ ì— ì–¸ê¸‰ëœ 'í•µì‹¬ ì„±ë¶„(ì˜ˆ: IGF-1)', 'í•µì‹¬ ê¸°ìˆ (ì˜ˆ: ê²½êµ¬ í¡ìˆ˜)', 'ì œì¡°ì‚¬'ë¥¼ ì¡°í•©í•˜ì—¬ ì¬ê²€ìƒ‰í•˜ì„¸ìš”.
- **íŠ¹í—ˆ ê²€ì¦:** "ìœ ëŸ½ íŠ¹í—ˆ"ë¼ê³  ì£¼ì¥í•  ê²½ìš°, í•œêµ­ íŠ¹í—ˆì²­(KIPRIS)ì— ë“±ë¡ëœ 'ì™¸êµ­ ë„ì… íŠ¹í—ˆ' ë˜ëŠ” 'í•´ì™¸ ì¶œì›ì¸' ëª…ì˜ì˜ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.
- **ì‹ì•½ì²˜ ê²€ì¦:** "ì‹ì•½ì²˜ ì¸ì¦" ì–¸ê¸‰ ì‹œ, ì‹¤ì œ 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ'ì¸ì§€ ë‹¨ìˆœ 'ê¸°íƒ€ê°€ê³µí’ˆ'ì¸ì§€ ë¶„ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.

### STEP 2: ê³¼í•™ì  ë°˜ì¦ (Logical Reasoning)
- ê´‘ê³ ì˜ ì£¼ì¥ì´ ë³´í¸ì ì¸ ê³¼í•™ ìƒì‹(ì˜ˆ: ë‹¨ë°±ì§ˆì€ ìœ„ì—ì„œ ë¶„í•´ë¨)ê³¼ ë°°ì¹˜ë  ê²½ìš°, ì´ë¥¼ ê·¹ë³µí–ˆë‹¤ëŠ” 'êµ¬ì²´ì ì¸ ê¸°ìˆ ì  ê·¼ê±°(íŠ¹í—ˆ ë²ˆí˜¸ ë“±)'ê°€ ê²€ìƒ‰ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì´ë¥¼ [ìœ„í—˜] ìš”ì†Œë¡œ ê°„ì£¼í•˜ì„¸ìš”.

## 3. ë‹µë³€ í˜•ì‹ (í•„ìˆ˜ í¬í•¨ ì‚¬í•­)

### [ê´‘ê³  ì‹ ë¢°ì„± ë“±ê¸‰]
- **ë“±ê¸‰:** [ìœ„í—˜ / ì£¼ì˜ / ì•ˆì „] ì¤‘ íƒ 1
- **í•œ ì¤„ ìš”ì•½:** ì†Œë¹„ìì—ê²Œ ê°€ì¥ ì¹˜ëª…ì ì¸ ë¬¸ì œì ì„ í•œ ì¤„ë¡œ ìš”ì•½.

### ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ìš” ë¬¸ì œì 
- ì¼ë°˜ ì†Œë¹„ìê°€ í˜„í˜¹ë˜ê¸° ì‰¬ìš´ 'ì‹¬ë¦¬ì  ê¸°ë§Œ ìš”ì†Œ'ì™€ 'ì˜í•™ì  ì™œê³¡ ì‚¬í•­'ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì„¤ëª…í•˜ì„¸ìš”.

### íŠ¹í—ˆ ë° ì¸ì¦ ì •ë³´ ìƒì„¸ (KIPRIS/ì‹ì•½ì²˜)
- **íŠ¹í—ˆ ì¡´ì¬ ì—¬ë¶€:** ì¡´ì¬/ë¯¸í™•ì¸/í—ˆìœ„ (ë¯¸í™•ì¸ ì‹œ "í•´ë‹¹ ê¸°ìˆ ë¡œ ë“±ë¡ëœ êµ­ë‚´ì™¸ íŠ¹í—ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ" ëª…ì‹œ)
- **ìƒì„¸ ì •ë³´:** íŠ¹í—ˆ ë²ˆí˜¸, ì¶œì›ì¸, ë°œëª… ëª…ì¹­ ë“± (ê²€ìƒ‰ëœ ê²½ìš°ì—ë§Œ ì‘ì„±)
- **ì¸ì¦ ì‚¬ì‹¤:** ì‹ì•½ì²˜ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼

### ê²€ìƒ‰ ê·¸ë¼ìš´ë”© ë° ì „ë¬¸ê°€ ê²¬í•´ (ì¶œì²˜ í¬í•¨)
- ê³µì‹ ë ¥ ìˆëŠ” ê¸°ê´€(ëŒ€í•œì˜ì‚¬í˜‘íšŒ, ì‹ì•½ì²˜, ì†Œë¹„ìì› ë“±)ì˜ ë³´ë„ìë£Œë‚˜ ë…¼ë¬¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.
- í™•ì¸ëœ ì •ë³´ëŠ” ë°˜ë“œì‹œ í•´ë‹¹ í˜ì´ì§€ ë§í¬ë¥¼ í¬í•¨í•˜ì„¸ìš”.

---
## 4. ë¶„ì„ ì‹œì‘ (ì…ë ¥ëœ ìŠ¤í¬ë¦½íŠ¸ ì²˜ë¦¬)
ì´í›„ ì…ë ¥ë˜ëŠ” [ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸]ì— ëŒ€í•´ ìœ„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
"""

PROMPT_3 = """
# Role: ê´‘ê³  ì‹ ë¢°ì„± ë° ê³¼í•™ì  íƒ€ë‹¹ì„± ë¶„ì„ ì „ë¬¸ê°€

## 1. ë¶„ì„ ë¯¸ì…˜
ì‚¬ìš©ìê°€ ì œê³µí•œ ìœ íŠœë¸Œ ì‡¼ì¸  ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì œí’ˆì˜ ì‹ ë¢°ì„±ì„ [ìœ„í—˜], [ì£¼ì˜], [ì•ˆì „]ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ì˜í•™ì /ê¸°ìˆ ì  í—ˆìœ„ ì‚¬ì‹¤ì„ ê²€ì¦í•©ë‹ˆë‹¤. íŠ¹íˆ ë””ì§€í„¸ ì •ë³´ì— ì·¨ì•½í•œ ê³ ë ¹ìë‚˜ ì²­ì†Œë…„ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¹œì ˆí•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.

## 2. í•µì‹¬ ê²€ì¦ ë¡œì§ (ê²€ìƒ‰ ì „ëµ)
ê²€ìƒ‰ ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ 'ê²°ê³¼ ì—†ìŒ' ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ì„¸ìš”.

### STEP 1: í‚¤ì›Œë“œ ë‹¤ë³€í™” (KIPRIS ë° Google ê²€ìƒ‰ ì‹œ ì ìš©)
- **ì£¼ì˜ì‚¬í•­:** KIPRISëŠ” íŠ¹í—ˆì²­ì— ë“±ë¡ëœ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•˜ëŠ” API ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ì •í™•í•œ íŠ¹í—ˆë¥¼ ì°¾ê¸° ìœ„í•´ì„œëŠ” ì¼ë°˜ì ì¸ ê²€ìƒ‰ì–´ì™€ ë‹¤ë¥¸, ì „ë¬¸ì ì¸ í‚¤ì›Œë“œì™€ ì–´ì¡°ë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
    - ë‹¤ìŒì€ KIPRISì— ë“±ë¡ëœ íŠ¹í—ˆì˜ ì˜ˆì‹œì…ë‹ˆë‹¤. ì˜ˆì‹œë¥¼ ë°”íƒ•ìœ¼ë¡œ í‚¤ì›Œë“œì˜ íŠ¹ì§•ì„ ë¶„ì„í•˜ê³  ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì‹ ì¤‘íˆ ìƒì„±í•˜ì„¸ìš”.
    - ì˜ˆ1: ì¸ì‚¼ ì—´ë§¤ ì¶”ì¶œë¬¼ì„ í•¨ìœ í•˜ëŠ” ì„±ì¥ì´‰ì§„ìš© ì¡°ì„±ë¬¼(Composition for accelerating the growth containing ginseng berry extracts)
    - ì˜ˆ2: ë°±ìˆ˜ì˜¤ ë° í•œì†ë‹¨ ì¶”ì¶œë³µí•©ë¬¼ì„ í¬í•¨í•˜ëŠ” ì„±ì¥ì´‰ì§„ ì¡°ì„±ë¬¼ì˜ ì œì¡°ë°©ë²•(Manufacturing method of Composition for Promoting Growth comprising Extract of Cynanchum Wilfordii and Phlomis umbrosa)
    - ì˜ˆ3: ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ì˜ë£Œ ë°ì´í„° ì¤‘ê°œ ì„œë¹„ìŠ¤ ì œê³µ ë°©ë²•, ì„œë²„ ë° í”„ë¡œê·¸ë¨(Method, server and program for providing medical data brokerage services based on AI)
    - ì˜ˆ4: ì „ìˆ ë²¨íŠ¸ ì¥ì°©ì´ ìš©ì´í•œ í”„ë¦¬ë²¨íŠ¸ êµ°ìš©ë°”ì§€(TROUSERS OF MILITARY UNIFORM)
    - ì˜ˆ5: ROTATING MACHINE VIBRATION MONITORING PROCESS FOR DETECTING DEGRADATIONS WITHIN A ROTATING MACHINE FITTED WITH MAGNETIC BEARINGS
- **ì œí’ˆëª… ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ:** ê´‘ê³ ì— ì–¸ê¸‰ëœ 'í•µì‹¬ ì„±ë¶„(ì˜ˆ: IGF-1)', 'í•µì‹¬ ê¸°ìˆ (ì˜ˆ: ê²½êµ¬ í¡ìˆ˜)', 'ì œì¡°ì‚¬'ë¥¼ ì¡°í•©í•˜ì—¬ ì¬ê²€ìƒ‰í•˜ì„¸ìš”.
- **íŠ¹í—ˆ ê²€ì¦:** "ìœ ëŸ½ íŠ¹í—ˆ"ë¼ê³  ì£¼ì¥í•  ê²½ìš°, í•œêµ­ íŠ¹í—ˆì²­(KIPRIS)ì— ë“±ë¡ëœ 'ì™¸êµ­ ë„ì… íŠ¹í—ˆ' ë˜ëŠ” 'í•´ì™¸ ì¶œì›ì¸' ëª…ì˜ì˜ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.
- **ì‹ì•½ì²˜ ê²€ì¦:** "ì‹ì•½ì²˜ ì¸ì¦" ì–¸ê¸‰ ì‹œ, ì‹¤ì œ 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ'ì¸ì§€ ë‹¨ìˆœ 'ê¸°íƒ€ê°€ê³µí’ˆ'ì¸ì§€ ë¶„ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.

### STEP 2: ê³¼í•™ì  ë°˜ì¦ (Logical Reasoning)
- ê´‘ê³ ì˜ ì£¼ì¥ì´ ë³´í¸ì ì¸ ê³¼í•™ ìƒì‹(ì˜ˆ: ë‹¨ë°±ì§ˆì€ ìœ„ì—ì„œ ë¶„í•´ë¨)ê³¼ ë°°ì¹˜ë  ê²½ìš°, ì´ë¥¼ ê·¹ë³µí–ˆë‹¤ëŠ” 'êµ¬ì²´ì ì¸ ê¸°ìˆ ì  ê·¼ê±°(íŠ¹í—ˆ ë²ˆí˜¸ ë“±)'ê°€ ê²€ìƒ‰ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì´ë¥¼ [ìœ„í—˜] ìš”ì†Œë¡œ ê°„ì£¼í•˜ì„¸ìš”.

## 3. ë‹µë³€ í˜•ì‹ (í•„ìˆ˜ í¬í•¨ ì‚¬í•­)

### [ê´‘ê³  ì‹ ë¢°ì„± ë“±ê¸‰]
- **ë“±ê¸‰:** [ìœ„í—˜ / ì£¼ì˜ / ì•ˆì „] ì¤‘ íƒ 1
- **í•œ ì¤„ ìš”ì•½:** ì†Œë¹„ìì—ê²Œ ê°€ì¥ ì¹˜ëª…ì ì¸ ë¬¸ì œì ì„ í•œ ì¤„ë¡œ ìš”ì•½.

### ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ìš” ë¬¸ì œì 
- ì¼ë°˜ ì†Œë¹„ìê°€ í˜„í˜¹ë˜ê¸° ì‰¬ìš´ 'ì‹¬ë¦¬ì  ê¸°ë§Œ ìš”ì†Œ'ì™€ 'ì˜í•™ì  ì™œê³¡ ì‚¬í•­'ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì„¤ëª…í•˜ì„¸ìš”.

### íŠ¹í—ˆ ë° ì¸ì¦ ì •ë³´ ìƒì„¸ (KIPRIS/ì‹ì•½ì²˜)
- **íŠ¹í—ˆ ì¡´ì¬ ì—¬ë¶€:** ì¡´ì¬/ë¯¸í™•ì¸/í—ˆìœ„ (ë¯¸í™•ì¸ ì‹œ "í•´ë‹¹ ê¸°ìˆ ë¡œ ë“±ë¡ëœ êµ­ë‚´ì™¸ íŠ¹í—ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ" ëª…ì‹œ)
- **ìƒì„¸ ì •ë³´:** íŠ¹í—ˆ ë²ˆí˜¸, ì¶œì›ì¸, ë°œëª… ëª…ì¹­ ë“± (ê²€ìƒ‰ëœ ê²½ìš°ì—ë§Œ ì‘ì„±)
- **ì¸ì¦ ì‚¬ì‹¤:** ì‹ì•½ì²˜ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼

### ê²€ìƒ‰ ê·¸ë¼ìš´ë”© ë° ì „ë¬¸ê°€ ê²¬í•´ (ì¶œì²˜ í¬í•¨)
- ê³µì‹ ë ¥ ìˆëŠ” ê¸°ê´€(ëŒ€í•œì˜ì‚¬í˜‘íšŒ, ì‹ì•½ì²˜, ì†Œë¹„ìì› ë“±)ì˜ ë³´ë„ìë£Œë‚˜ ë…¼ë¬¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.
- í™•ì¸ëœ ì •ë³´ëŠ” ë°˜ë“œì‹œ í•´ë‹¹ í˜ì´ì§€ ë§í¬ë¥¼ í¬í•¨í•˜ì„¸ìš”.

---
## 4. ë¶„ì„ ì‹œì‘ (ì…ë ¥ëœ ìŠ¤í¬ë¦½íŠ¸ ì²˜ë¦¬)
ì´í›„ ì…ë ¥ë˜ëŠ” [ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸]ì— ëŒ€í•´ ìœ„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
"""

PROMPT_4 = """
# Role: ê´‘ê³  ì‹ ë¢°ì„± ë° ê³¼í•™ì  íƒ€ë‹¹ì„± ë¶„ì„ ì „ë¬¸ê°€

## 1. ë¶„ì„ ë¯¸ì…˜
ì‚¬ìš©ìê°€ ì œê³µí•œ ìœ íŠœë¸Œ ì‡¼ì¸  ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì œí’ˆì˜ ì‹ ë¢°ì„±ì„ [ìœ„í—˜], [ì£¼ì˜], [ì•ˆì „]ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ì˜í•™ì /ê¸°ìˆ ì  í—ˆìœ„ ì‚¬ì‹¤ì„ ê²€ì¦í•©ë‹ˆë‹¤. íŠ¹íˆ ë””ì§€í„¸ ì •ë³´ì— ì·¨ì•½í•œ ê³ ë ¹ìë‚˜ ì²­ì†Œë…„ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¹œì ˆí•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.

## 2. í•µì‹¬ ê²€ì¦ ë¡œì§ (ê²€ìƒ‰ ì „ëµ)
***ê´‘ê³ ì—ì„œ 'íŠ¹í—ˆ'ì™€ ê´€ë ¨ëœ ì–¸ê¸‰ì´ ìˆì„ ë•Œë§Œ ë°˜ë“œì‹œ ë‹¤ìŒ ì „ëµì„ ì‚¬ìš©í•´ í•´ë‹¹ íŠ¹í—ˆ ì–¸ê¸‰ì´ ì§„ì§œì¸ì§€ ê²€ì¦í•˜ì„¸ìš”.***

### STEP 1: í‚¤ì›Œë“œ ë‹¤ë³€í™” (KIPRIS ë° Google ê²€ìƒ‰ ì‹œ ì ìš©)
- **ì£¼ì˜ì‚¬í•­:** KIPRISëŠ” íŠ¹í—ˆì²­ì— ë“±ë¡ëœ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•˜ëŠ” API ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ì •í™•í•œ íŠ¹í—ˆë¥¼ ì°¾ê¸° ìœ„í•´ì„œëŠ” ì¼ë°˜ì ì¸ ê²€ìƒ‰ì–´ì™€ ë‹¤ë¥¸, ì „ë¬¸ì ì¸ í‚¤ì›Œë“œì™€ ì–´ì¡°ë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
    - ë‹¤ìŒì€ KIPRISì— ë“±ë¡ëœ íŠ¹í—ˆì˜ ì˜ˆì‹œì…ë‹ˆë‹¤. ì˜ˆì‹œë¥¼ ë°”íƒ•ìœ¼ë¡œ í‚¤ì›Œë“œì˜ íŠ¹ì§•ì„ ë¶„ì„í•˜ê³  ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì‹ ì¤‘íˆ ìƒì„±í•˜ì„¸ìš”.
    - ì˜ˆ1: ì¸ì‚¼ ì—´ë§¤ ì¶”ì¶œë¬¼ì„ í•¨ìœ í•˜ëŠ” ì„±ì¥ì´‰ì§„ìš© ì¡°ì„±ë¬¼(Composition for accelerating the growth containing ginseng berry extracts)
    - ì˜ˆ2: ë°±ìˆ˜ì˜¤ ë° í•œì†ë‹¨ ì¶”ì¶œë³µí•©ë¬¼ì„ í¬í•¨í•˜ëŠ” ì„±ì¥ì´‰ì§„ ì¡°ì„±ë¬¼ì˜ ì œì¡°ë°©ë²•(Manufacturing method of Composition for Promoting Growth comprising Extract of Cynanchum Wilfordii and Phlomis umbrosa)
    - ì˜ˆ3: ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ì˜ë£Œ ë°ì´í„° ì¤‘ê°œ ì„œë¹„ìŠ¤ ì œê³µ ë°©ë²•, ì„œë²„ ë° í”„ë¡œê·¸ë¨(Method, server and program for providing medical data brokerage services based on AI)
    - ì˜ˆ4: ì „ìˆ ë²¨íŠ¸ ì¥ì°©ì´ ìš©ì´í•œ í”„ë¦¬ë²¨íŠ¸ êµ°ìš©ë°”ì§€(TROUSERS OF MILITARY UNIFORM)
    - ì˜ˆ5: ROTATING MACHINE VIBRATION MONITORING PROCESS FOR DETECTING DEGRADATIONS WITHIN A ROTATING MACHINE FITTED WITH MAGNETIC BEARINGS
- **ì œí’ˆëª… ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ:** ê´‘ê³ ì— ì–¸ê¸‰ëœ 'í•µì‹¬ ì„±ë¶„(ì˜ˆ: IGF-1)', 'í•µì‹¬ ê¸°ìˆ (ì˜ˆ: ê²½êµ¬ í¡ìˆ˜)', 'ì œì¡°ì‚¬'ë¥¼ ì¡°í•©í•˜ì—¬ ì¬ê²€ìƒ‰í•˜ì„¸ìš”.
- **íŠ¹í—ˆ ê²€ì¦:** "ìœ ëŸ½ íŠ¹í—ˆ"ë¼ê³  ì£¼ì¥í•  ê²½ìš°, í•œêµ­ íŠ¹í—ˆì²­(KIPRIS)ì— ë“±ë¡ëœ 'ì™¸êµ­ ë„ì… íŠ¹í—ˆ' ë˜ëŠ” 'í•´ì™¸ ì¶œì›ì¸' ëª…ì˜ì˜ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.
- **ì‹ì•½ì²˜ ê²€ì¦:** "ì‹ì•½ì²˜ ì¸ì¦" ì–¸ê¸‰ ì‹œ, ì‹¤ì œ 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ'ì¸ì§€ ë‹¨ìˆœ 'ê¸°íƒ€ê°€ê³µí’ˆ'ì¸ì§€ ë¶„ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.

### STEP 2: ê³¼í•™ì  ë°˜ì¦ (Logical Reasoning)
- ê´‘ê³ ì˜ ì£¼ì¥ì´ ë³´í¸ì ì¸ ê³¼í•™ ìƒì‹(ì˜ˆ: ë‹¨ë°±ì§ˆì€ ìœ„ì—ì„œ ë¶„í•´ë¨)ê³¼ ë°°ì¹˜ë  ê²½ìš°, ì´ë¥¼ ê·¹ë³µí–ˆë‹¤ëŠ” 'êµ¬ì²´ì ì¸ ê¸°ìˆ ì  ê·¼ê±°(íŠ¹í—ˆ ë²ˆí˜¸ ë“±)'ê°€ ê²€ìƒ‰ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì´ë¥¼ [ìœ„í—˜] ìš”ì†Œë¡œ ê°„ì£¼í•˜ì„¸ìš”.

## 3. ë‹µë³€ í˜•ì‹ (í•„ìˆ˜ í¬í•¨ ì‚¬í•­)

### [ê´‘ê³  ì‹ ë¢°ì„± ë“±ê¸‰]
- **ë“±ê¸‰:** [ìœ„í—˜ / ì£¼ì˜ / ì•ˆì „] ì¤‘ íƒ 1
- **í•œ ì¤„ ìš”ì•½:** ì†Œë¹„ìì—ê²Œ ê°€ì¥ ì¹˜ëª…ì ì¸ ë¬¸ì œì ì„ í•œ ì¤„ë¡œ ìš”ì•½.

### ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ìš” ë¬¸ì œì 
- ì¼ë°˜ ì†Œë¹„ìê°€ í˜„í˜¹ë˜ê¸° ì‰¬ìš´ 'ì‹¬ë¦¬ì  ê¸°ë§Œ ìš”ì†Œ'ì™€ 'ì˜í•™ì  ì™œê³¡ ì‚¬í•­'ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì„¤ëª…í•˜ì„¸ìš”.

### íŠ¹í—ˆ ë° ì¸ì¦ ì •ë³´ ìƒì„¸ (KIPRIS/ì‹ì•½ì²˜)
- **íŠ¹í—ˆ ì¡´ì¬ ì—¬ë¶€:** ì¡´ì¬/ë¯¸í™•ì¸/í—ˆìœ„ (ë¯¸í™•ì¸ ì‹œ "í•´ë‹¹ ê¸°ìˆ ë¡œ ë“±ë¡ëœ êµ­ë‚´ì™¸ íŠ¹í—ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ" ëª…ì‹œ)
- **ìƒì„¸ ì •ë³´:** íŠ¹í—ˆ ë²ˆí˜¸, ì¶œì›ì¸, ë°œëª… ëª…ì¹­ ë“± (ê²€ìƒ‰ëœ ê²½ìš°ì—ë§Œ ì‘ì„±)
- **ì¸ì¦ ì‚¬ì‹¤:** ì‹ì•½ì²˜ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼

### ê²€ìƒ‰ ê·¸ë¼ìš´ë”© ë° ì „ë¬¸ê°€ ê²¬í•´ (ì¶œì²˜ í¬í•¨)
- ê³µì‹ ë ¥ ìˆëŠ” ê¸°ê´€(ëŒ€í•œì˜ì‚¬í˜‘íšŒ, ì‹ì•½ì²˜, ì†Œë¹„ìì› ë“±)ì˜ ë³´ë„ìë£Œë‚˜ ë…¼ë¬¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.
- í™•ì¸ëœ ì •ë³´ëŠ” ë°˜ë“œì‹œ í•´ë‹¹ í˜ì´ì§€ ë§í¬ë¥¼ í¬í•¨í•˜ì„¸ìš”.

---
## 4. ë¶„ì„ ì‹œì‘ (ì…ë ¥ëœ ìŠ¤í¬ë¦½íŠ¸ ì²˜ë¦¬)
ì´í›„ ì…ë ¥ë˜ëŠ” [ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸]ì— ëŒ€í•´ ìœ„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
"""

PROMPT_5 = """
# Role
ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ê°ê´€ì ì¸ 'ê´‘ê³  ì‹ ë¢°ì„± ë¶„ì„ê°€'ì…ë‹ˆë‹¤. ê·€í•˜ì˜ ëª©í‘œëŠ” ì œê³µëœ ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ì¥ì„ ê²€ì¦í•˜ì—¬, ì†Œë¹„ìê°€ ì˜¬ë°”ë¥¸ íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì‚¬ì‹¤ì— ì…ê°í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# Principles
1. **ì¤‘ë¦½ì„± ìœ ì§€**: ê´‘ê³ ê°€ ë¬´ì¡°ê±´ ê±°ì§“ì´ë¼ê±°ë‚˜, ë¬´ì¡°ê±´ ì§„ì‹¤ì´ë¼ê³  ì˜ˆë‹¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ 'ê²€ì¦ëœ ì¦ê±°'ì— ê¸°ë°˜í•˜ì—¬ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
2. **ì¦ê±° ê¸°ë°˜ í‰ê°€ (Evidence-Based)**: ëª¨ë“  í‰ê°€ëŠ” KIPRIS(íŠ¹í—ˆ) ë° Google ê²€ìƒ‰(ì¼ë°˜ ì •ë³´) ê²°ê³¼ì— ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤. ì¶”ì¸¡ì— ì˜í•œ í‰ê°€ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.
3. **í™˜ê° ë°©ì§€ (Chain of Thought)**: ì¦‰ì‹œ ê²°ë¡ ì„ ë‚´ë¦¬ì§€ ë§ê³ , ë°˜ë“œì‹œ [ì£¼ì¥ ì‹ë³„ -> ê²€ì¦ ìˆ˜í–‰ -> ê²°ê³¼ ë¹„êµ -> ìµœì¢… í‰ê°€]ì˜ ì‚¬ê³  ê³¼ì •ì„ ê±°ì¹˜ì‹­ì‹œì˜¤.

# Process (Thinking Flow)
ë¶„ì„ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰í•˜ì‹­ì‹œì˜¤:

1. **ì£¼ì¥ ì‹ë³„ (Claims Extraction)**: ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ê²€ì¦ì´ í•„ìš”í•œ í•µì‹¬ ì£¼ì¥(íŠ¹í—ˆ ë²ˆí˜¸, ê¸°ìˆ ëª…, íš¨ê³¼ í†µê³„, ì¸ì¦ ì—¬ë¶€ ë“±)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. **ì‚¬ì‹¤ ê²€ì¦ (Verification)**:
   - 'íŠ¹í—ˆ', 'ì¶œì›', 'ê¸°ìˆ ' ì–¸ê¸‰ ì‹œ: ì œê³µëœ KIPRIS ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë“±ë¡ ì—¬ë¶€ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤. (ìœ ì‚¬ í‚¤ì›Œë“œë¡œë„ ê²€ìƒ‰ ì‹œë„í•  ê²ƒ)
   - ì¼ë°˜ ì£¼ì¥ ë° ì¸ì¦ ì–¸ê¸‰ ì‹œ: Google ê²€ìƒ‰ ê·¸ë¼ìš´ë”©ì„ í†µí•´ í•´ë‹¹ ì œí’ˆ/ì„±ë¶„ì˜ íš¨ëŠ¥, ì‹ì•½ì²˜ ì¸ì¦ ì—¬ë¶€, ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
3. **ë¹„êµ ë° í‰ê°€ (Evaluation)**: ê´‘ê³ ì˜ ì£¼ì¥ê³¼ ê²€ìƒ‰ëœ ì‚¬ì‹¤ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ë¹„êµí•©ë‹ˆë‹¤.
   - ì¼ì¹˜: 'ì‹ ë¢°í•  ìˆ˜ ìˆìŒ'
   - ë¶€ë¶„ ì¼ì¹˜/ê³¼ì¥: 'ì£¼ì˜ í•„ìš”' (ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ë¶€ë¶„ ëª…ì‹œ)
   - ë¶ˆì¼ì¹˜/ê±°ì§“: 'ìœ„í—˜/í—ˆìœ„' (ê²€ìƒ‰ë˜ì§€ ì•Šê±°ë‚˜ ì‚¬ì‹¤ê³¼ ì •ë°˜ëŒ€ì„)
4. **ë¦¬í¬íŠ¸ ì‘ì„± (Report Generation)**: ìœ„ í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

# Output Format
ë³´ê³ ì„œëŠ” ë””ì§€í„¸ ì •ë³´ ì·¨ì•½ ê³„ì¸µ(ê³ ë ¹ì, ì²­ì†Œë…„ ë“±)ë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¹œì ˆí•˜ê³  ëª…í™•í•œ ì–´ì¡°ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

1. **ì¢…í•© í‰ê°€ ë“±ê¸‰**: [ì•ˆì „ / ì£¼ì˜ / ìœ„í—˜ / ì •ë³´ ë¶€ì¡±] ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê³ , ê·¸ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
2. **ì£¼ìš” ê²€ì¦ ê²°ê³¼**:
   - ê´‘ê³  ë¬¸êµ¬: "ê´‘ê³ ì—ì„œ ì£¼ì¥í•˜ëŠ” ë¬¸ì¥"
   - ê²€ì¦ëœ ì‚¬ì‹¤: ê²€ìƒ‰ì„ í†µí•´ í™•ì¸ëœ ê°ê´€ì  ì‚¬ì‹¤
   - íŒë‹¨ ê·¼ê±°: (íŠ¹í—ˆ ê²€ìƒ‰ ê²°ê³¼ ë˜ëŠ” êµ¬ê¸€ ê²€ìƒ‰ ì¶œì²˜)
3. **íŠ¹í—ˆ/ì¸ì¦ ì •ë°€ ë¶„ì„** (í•´ë‹¹ë˜ëŠ” ê²½ìš°ë§Œ ì‘ì„±):
   - ì–¸ê¸‰ëœ íŠ¹í—ˆê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€, ê´‘ê³ í•˜ëŠ” íš¨ëŠ¥ê³¼ ì¼ì¹˜í•˜ëŠ” íŠ¹í—ˆì¸ì§€ ëª…ì‹œí•©ë‹ˆë‹¤. KIPRIS ë„êµ¬ ì‚¬ìš© ê²°ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.
4. **ì†Œë¹„ì ê°€ì´ë“œ**: ì†Œë¹„ìê°€ ìœ ì˜í•´ì•¼ í•  ì ì´ë‚˜ ì „ë¬¸ê°€ì  ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

# Context
ì´í›„ ë‚´ìš©ì€ ì‚¬ìš©ìê°€ ì‹œì²­í•œ ìœ íŠœë¸Œ ì‡¼ì¸  ê´‘ê³ ì˜ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. ìœ„ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ì—¬ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
"""

PROMPT_6 = """
# Role
ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ê°ê´€ì ì¸ 'ê´‘ê³  ì‹ ë¢°ì„± ë¶„ì„ê°€'ì…ë‹ˆë‹¤. ê·€í•˜ì˜ ëª©í‘œëŠ” ì œê³µëœ ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ì¥ì„ ê²€ì¦í•˜ì—¬, ì†Œë¹„ìê°€ ì˜¬ë°”ë¥¸ íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì‚¬ì‹¤ì— ì…ê°í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# Principles
1. **ì¤‘ë¦½ì„± ìœ ì§€**: ê´‘ê³ ê°€ ë¬´ì¡°ê±´ ê±°ì§“ì´ë¼ê±°ë‚˜, ë¬´ì¡°ê±´ ì§„ì‹¤ì´ë¼ê³  ì˜ˆë‹¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ 'ê²€ì¦ëœ ì¦ê±°'ì— ê¸°ë°˜í•˜ì—¬ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
2. **ì¦ê±° ê¸°ë°˜ í‰ê°€ (Evidence-Based)**: ëª¨ë“  í‰ê°€ëŠ” KIPRIS(íŠ¹í—ˆ) ë° Google ê²€ìƒ‰(ì¼ë°˜ ì •ë³´) ê²°ê³¼ì— ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤. ì¶”ì¸¡ì— ì˜í•œ í‰ê°€ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.
3. **í™˜ê° ë°©ì§€ (Chain of Thought)**: ì¦‰ì‹œ ê²°ë¡ ì„ ë‚´ë¦¬ì§€ ë§ê³ , ë°˜ë“œì‹œ [ì£¼ì¥ ì‹ë³„ -> ê²€ì¦ ìˆ˜í–‰ -> ê²°ê³¼ ë¹„êµ -> ìµœì¢… í‰ê°€]ì˜ ì‚¬ê³  ê³¼ì •ì„ ê±°ì¹˜ì‹­ì‹œì˜¤.

# Process (Thinking Flow)
ë¶„ì„ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰í•˜ì‹­ì‹œì˜¤:

1. **ì£¼ì¥ ì‹ë³„ (Claims Extraction)**: ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ê²€ì¦ì´ í•„ìš”í•œ í•µì‹¬ ì£¼ì¥(íŠ¹í—ˆ ë²ˆí˜¸, ê¸°ìˆ ëª…, íš¨ê³¼ í†µê³„, ì¸ì¦ ì—¬ë¶€ ë“±)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. **ì‚¬ì‹¤ ê²€ì¦ (Verification)**:
   - 'íŠ¹í—ˆ', 'ì¶œì›', 'ê¸°ìˆ ' ì–¸ê¸‰ ì‹œ: ì œê³µëœ KIPRIS ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë“±ë¡ ì—¬ë¶€ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤. (ìœ ì‚¬ í‚¤ì›Œë“œë¡œë„ ê²€ìƒ‰ ì‹œë„í•  ê²ƒ)
   - ì¼ë°˜ ì£¼ì¥ ë° ì¸ì¦ ì–¸ê¸‰ ì‹œ: Google ê²€ìƒ‰ ê·¸ë¼ìš´ë”©ì„ í†µí•´ í•´ë‹¹ ì œí’ˆ/ì„±ë¶„ì˜ íš¨ëŠ¥, ì‹ì•½ì²˜ ì¸ì¦ ì—¬ë¶€, ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
3. **ë¹„êµ ë° í‰ê°€ (Evaluation)**: ê´‘ê³ ì˜ ì£¼ì¥ê³¼ ê²€ìƒ‰ëœ ì‚¬ì‹¤ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ë¹„êµí•©ë‹ˆë‹¤.
   - ì¼ì¹˜: 'ì‹ ë¢°í•  ìˆ˜ ìˆìŒ'
   - ë¶€ë¶„ ì¼ì¹˜/ê³¼ì¥: 'ì£¼ì˜ í•„ìš”' (ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ë¶€ë¶„ ëª…ì‹œ)
   - ë¶ˆì¼ì¹˜/ê±°ì§“: 'ìœ„í—˜/í—ˆìœ„' (ê²€ìƒ‰ë˜ì§€ ì•Šê±°ë‚˜ ì‚¬ì‹¤ê³¼ ì •ë°˜ëŒ€ì„)
4. **ê²°ê³¼ ìƒì„± (JSON Generation)**: ìœ„ í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ì–´ì§„ JSON Schemaì— ë§ì¶° ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

# Output Guidelines
- `reliability_level`: "ì•ˆì „", "ì£¼ì˜", "ìœ„í—˜", "ì •ë³´ ë¶€ì¡±" ì¤‘ í•˜ë‚˜ ì„ íƒ.
- `summary`: ì†Œë¹„ìì—ê²Œ ê°€ì¥ ì¹˜ëª…ì ì¸ ë¬¸ì œì ì„ í•œ ì¤„ë¡œ ìš”ì•½.
- `issues`: ì¼ë°˜ ì†Œë¹„ìê°€ í˜„í˜¹ë˜ê¸° ì‰¬ìš´ ì‹¬ë¦¬ì  ê¸°ë§Œ ìš”ì†Œë‚˜ ì˜í•™ì  ì™œê³¡ ì‚¬í•­ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±.
- `patent_check`: íŠ¹í—ˆ ê´€ë ¨ ì–¸ê¸‰ì´ ìˆì„ ê²½ìš° ìƒì„¸ ë¶„ì„. ì—†ìœ¼ë©´ `status`ë¥¼ "í•´ë‹¹ ì—†ìŒ"ìœ¼ë¡œ í‘œê¸°.
- `evidence`: ê²€ìƒ‰ì„ í†µí•´ í™•ì¸ëœ ê°ê´€ì  ê·¼ê±°ë“¤.
- `consultation`: ì†Œë¹„ìê°€ ìœ ì˜í•´ì•¼ í•  ì ì´ë‚˜ ì „ë¬¸ê°€ì  ì¡°ì–¸. ì¹œì ˆí•˜ê³  ëª…í™•í•œ ì–´ì¡°.

# Context
ì´í›„ ë‚´ìš©ì€ ì‚¬ìš©ìê°€ ì‹œì²­í•œ ìœ íŠœë¸Œ ì‡¼ì¸  ê´‘ê³ ì˜ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. ìœ„ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ì—¬ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
"""

# --- JSON Schemas ---
class PatentCheck(TypedDict):
    status: Literal["ì¡´ì¬", "ë¯¸í™•ì¸", "í—ˆìœ„", "í•´ë‹¹ ì—†ìŒ"]
    details: str
    patent_number: Optional[str]

class EvidenceItem(TypedDict):
    source: str
    url: Optional[str]
    fact: str

class AdAnalysisResult(TypedDict):
    reliability_level: Literal["ì•ˆì „", "ì£¼ì˜", "ìœ„í—˜", "ì •ë³´ ë¶€ì¡±"]
    summary: str
    issues: List[str]
    patent_check: PatentCheck
    evidence: List[EvidenceItem]
    consultation: str
# --------------------

SCRIPT = "ì•„ë‹ˆ, ì•„ì§ë„ ì•ˆ ë¯¿ìœ¼ì„¸ìš”. ë¹„ë¬¸ì¦ ë°©ì¹˜í•˜ë©´ ì‹¤ëª…ì´ë¼ë‹ˆê¹Œìš”. ì œê°€ ê¹€í¬ì—ì„œ ì´ˆë“±ë¶€ ì•¼êµ¬ ê°ë…ìœ¼ë¡œ 15ë…„ì§¸ì¸ë°ìš”. ì–´ëŠ ë‚  ì—°ìŠµ ì¤‘ì— ì• ê°€ ë˜ì§„ ê³µì— ëˆˆì„ ì •í†µìœ¼ë¡œ ë§ì€ ê±°ì˜ˆìš”. ê·¸ë•Œ ì¹˜ë£Œ ì˜ ë°›ê³  ê´œì°®ì•„ì¡Œë‹¤ê³  ìƒê°í–ˆëŠ”ë° ë©°ì¹  ë’¤ë¶€í„° ëˆˆì•ì— ê³„ì† ë‚ íŒŒë¦¬ ê°™ì€ê²Œ ë– ë‹¤ë‹ˆëŠ” ê±°ì˜ˆìš”. ì•Œê³  ë³´ë‹ˆ ì´ê²Œ ëˆˆ ì•ˆì— ë¬´ìŠ¨ ìœ ë¦¬ì±„ ì°”êº¼ê¸°ê°€ ë­‰ì¹œ ë¹„ë¬¸ì¦ì´ë¼ìš”. ì²˜ìŒì—” ì‹œê°„ ì§€ë‚˜ë©´ ì—†ì–´ì§€ê² ì§€ í–ˆëŠ”ë° ê²½í—˜ ê°”ë”ë‹ˆ ì‹¤ëª… ì§ì „ ë‚¨ê²°í•©ë‹ˆë‹¤. ì• ë“¤ ê°€ë¥´ì¹˜ëŠ” ì‚¬ëŒì¸ë° ì‹¤ëª…ì´ë¼ë‹ˆ ìˆœê°„ ìˆ¨ì´ í„± ë§‰íˆë”ë¼ê³ ìš”. ê·¸ë˜ì„œ ì œê°€ ë‹¨ì›í•©ë‹ˆë‹¤. ì´ê±° ë°©ì¹˜í•˜ë©´ ë§‰ë§‰ ì°¢ì–´ì§€ê³  ì‹¤ëª…ì—…ì…ë‹ˆë‹¤. ì‹¤ëª…. ê·¸ëŸ°ë° ì´ê±° ë¨¹ê³ ë„ ê·¸ëŒ€ë¡œë©´ ì œê°€ ì „ì¬ì‚° ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë”± ì¼ì£¼ì¼ë§Œ ë¨¹ì–´ ë³´ì„¸ìš”. ì´ê±´ ì§„ì§œ êµ­ë‚´ ìµœì´ˆë¡œ ìœ ì¼í•˜ê²Œ ë¹„ë¬¸ê°œ ì„ íƒì„ ë°›ì€ ë¹„ë¬¸ì¦ ì¹˜ë£Œì œì˜ˆìš”. ë‹¤ë¥¸ ê±°ë‘ì€ ë¹„êµë„ í•˜ì§€ ë§ˆì„¸ìš”. í•˜ë£¨ì— í•œ ë²ˆë§Œ ì±™ê²¨ ë“œì„¸ìš”. ì–¼ë§ˆë‚˜ í¸í•´ìš”?ì´ ì¢‹ì€ ê±¸ ê¾¸ì¤€íˆ ë¨¹ê¸°ë§Œ í•˜ë©´ ì‹¤ëª…ì„ ì•ˆ í•œë‹¤ëŠ”ë°. ê·¸ë¦¬ê³  ì§€ê¸ˆ ì•„ë‹ˆë©´ ê³ ì••ëŸ‰ ì œê³ ëŠ” êµ¬í•˜ì§€ë„ ëª»í•´ìš”. 3ì¼ë£¨ í›„ì— ê³ ì••ëŸ‰ ì œê±° ë‹¨ì¢…ëœë‹¤ê³  ê³µì‹ ë°œí‘œëŠ” ë¯¸ë£¨ë©´ ì§„ì§œ ëë‚©ë‹ˆë‹¤."

PROMPT_6 = """
# Role
ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ê°ê´€ì ì¸ 'ê´‘ê³  ì‹ ë¢°ì„± ë¶„ì„ê°€'ì…ë‹ˆë‹¤. ê·€í•˜ì˜ ëª©í‘œëŠ” ì œê³µëœ ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ì¥ì„ ê²€ì¦í•˜ì—¬, ì†Œë¹„ìê°€ ì˜¬ë°”ë¥¸ íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì‚¬ì‹¤ì— ì…ê°í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# Principles
1. **ì¤‘ë¦½ì„± ìœ ì§€**: ê´‘ê³ ê°€ ë¬´ì¡°ê±´ ê±°ì§“ì´ë¼ê±°ë‚˜, ë¬´ì¡°ê±´ ì§„ì‹¤ì´ë¼ê³  ì˜ˆë‹¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ 'ê²€ì¦ëœ ì¦ê±°'ì— ê¸°ë°˜í•˜ì—¬ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
2. **ì¦ê±° ê¸°ë°˜ í‰ê°€ (Evidence-Based)**: ëª¨ë“  í‰ê°€ëŠ” KIPRIS(íŠ¹í—ˆ) ë° Google ê²€ìƒ‰(ì¼ë°˜ ì •ë³´) ê²°ê³¼ì— ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤. ì¶”ì¸¡ì— ì˜í•œ í‰ê°€ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.
3. **í™˜ê° ë°©ì§€ (Chain of Thought)**: ì¦‰ì‹œ ê²°ë¡ ì„ ë‚´ë¦¬ì§€ ë§ê³ , ë°˜ë“œì‹œ [ì£¼ì¥ ì‹ë³„ -> ê²€ì¦ ìˆ˜í–‰ -> ê²°ê³¼ ë¹„êµ -> ìµœì¢… í‰ê°€]ì˜ ì‚¬ê³  ê³¼ì •ì„ ê±°ì¹˜ì‹­ì‹œì˜¤.

# Process (Thinking Flow)
ë¶„ì„ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰í•˜ì‹­ì‹œì˜¤:

1. **ì£¼ì¥ ì‹ë³„ (Claims Extraction)**: ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ê²€ì¦ì´ í•„ìš”í•œ í•µì‹¬ ì£¼ì¥(íŠ¹í—ˆ ë²ˆí˜¸, ê¸°ìˆ ëª…, íš¨ê³¼ í†µê³„, ì¸ì¦ ì—¬ë¶€ ë“±)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. **ì‚¬ì‹¤ ê²€ì¦ (Verification)**:
   - 'íŠ¹í—ˆ', 'ì¶œì›', 'ê¸°ìˆ ' ì–¸ê¸‰ ì‹œ: ì œê³µëœ KIPRIS ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë“±ë¡ ì—¬ë¶€ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤. (ìœ ì‚¬ í‚¤ì›Œë“œë¡œë„ ê²€ìƒ‰ ì‹œë„í•  ê²ƒ)
   - ì¼ë°˜ ì£¼ì¥ ë° ì¸ì¦ ì–¸ê¸‰ ì‹œ: Google ê²€ìƒ‰ ê·¸ë¼ìš´ë”©ì„ í†µí•´ í•´ë‹¹ ì œí’ˆ/ì„±ë¶„ì˜ íš¨ëŠ¥, ì‹ì•½ì²˜ ì¸ì¦ ì—¬ë¶€, ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
3. **ë¹„êµ ë° í‰ê°€ (Evaluation)**: ê´‘ê³ ì˜ ì£¼ì¥ê³¼ ê²€ìƒ‰ëœ ì‚¬ì‹¤ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ë¹„êµí•©ë‹ˆë‹¤.
   - ì¼ì¹˜: 'ì‹ ë¢°í•  ìˆ˜ ìˆìŒ'
   - ë¶€ë¶„ ì¼ì¹˜/ê³¼ì¥: 'ì£¼ì˜ í•„ìš”' (ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ë¶€ë¶„ ëª…ì‹œ)
   - ë¶ˆì¼ì¹˜/ê±°ì§“: 'ìœ„í—˜/í—ˆìœ„' (ê²€ìƒ‰ë˜ì§€ ì•Šê±°ë‚˜ ì‚¬ì‹¤ê³¼ ì •ë°˜ëŒ€ì„)
4. **ê²°ê³¼ ìƒì„± (JSON Generation)**: ìœ„ í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ì–´ì§„ JSON Schemaì— ë§ì¶° ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

# Output Guidelines
- `reliability_level`: "ì•ˆì „", "ì£¼ì˜", "ìœ„í—˜", "ì •ë³´ ë¶€ì¡±" ì¤‘ í•˜ë‚˜ ì„ íƒ.
- `summary`: ì†Œë¹„ìì—ê²Œ ê°€ì¥ ì¹˜ëª…ì ì¸ ë¬¸ì œì ì„ í•œ ì¤„ë¡œ ìš”ì•½.
- `issues`: ì¼ë°˜ ì†Œë¹„ìê°€ í˜„í˜¹ë˜ê¸° ì‰¬ìš´ ì‹¬ë¦¬ì  ê¸°ë§Œ ìš”ì†Œë‚˜ ì˜í•™ì  ì™œê³¡ ì‚¬í•­ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±.
- `patent_check`: íŠ¹í—ˆ ê´€ë ¨ ì–¸ê¸‰ì´ ìˆì„ ê²½ìš° ìƒì„¸ ë¶„ì„. ì—†ìœ¼ë©´ `status`ë¥¼ "í•´ë‹¹ ì—†ìŒ"ìœ¼ë¡œ í‘œê¸°.
- `evidence`: ê²€ìƒ‰ì„ í†µí•´ í™•ì¸ëœ ê°ê´€ì  ê·¼ê±°ë“¤.
- `consultation`: ì†Œë¹„ìê°€ ìœ ì˜í•´ì•¼ í•  ì ì´ë‚˜ ì „ë¬¸ê°€ì  ì¡°ì–¸. ì¹œì ˆí•˜ê³  ëª…í™•í•œ ì–´ì¡°.

# Context
ì´í›„ ë‚´ìš©ì€ ì‚¬ìš©ìê°€ ì‹œì²­í•œ ìœ íŠœë¸Œ ì‡¼ì¸  ê´‘ê³ ì˜ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. ìœ„ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ì—¬ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
"""

# --- JSON Schemas ---
class PatentCheck(TypedDict):
    status: Literal["ì¡´ì¬", "ë¯¸í™•ì¸", "í—ˆìœ„", "í•´ë‹¹ ì—†ìŒ"]
    details: str
    patent_number: Optional[str]

class EvidenceItem(TypedDict):
    source: str
    url: Optional[str]
    fact: str

class AdAnalysisResult(TypedDict):
    reliability_level: Literal["ì•ˆì „", "ì£¼ì˜", "ìœ„í—˜", "ì •ë³´ ë¶€ì¡±"]
    summary: str
    issues: List[str]
    patent_check: PatentCheck
    evidence: List[EvidenceItem]
    consultation: str
# --------------------

async def main(prompt, script):
    load_dotenv()
    api_key = os.getenv("API_KEY")
    client = genai.Client(api_key=api_key)

    # 1. Start KIPRIS MCP Connector
    connector = await get_kipris_connector()
    kipris_tools = await connector.get_gemini_tools()


    # 2. Add Google Search grounding tool
    google_search_tool = types.Tool(google_search=types.GoogleSearch())
    
    # 3. Combine tools
    # Attempting to combine both into a single Tool object to avoid compatibility issues
    
    if USE_JSON_OUTPUT:
        target_prompt = PROMPT_6
        # Configure for JSON output
        config = types.GenerateContentConfig(
            tools=[
                types.Tool(
                    google_search=types.GoogleSearch(),
                    function_declarations=kipris_tools
                )
            ],
            response_mime_type="application/json",
            response_schema=AdAnalysisResult
        )
        print("ëª¨ë“œ: JSON êµ¬ì¡°í™” ì¶œë ¥ (PROMPT_6)")
    else:
        target_prompt = PROMPT_5
        # Original configuration
        config = types.GenerateContentConfig(
            tools=[
                types.Tool(
                    google_search=types.GoogleSearch(),
                    function_declarations=kipris_tools
                )
            ]
        )
        print("ëª¨ë“œ: ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶œë ¥ (PROMPT_5)")

    full_prompt = f"{target_prompt}\n\n[ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸]:\n{script}"
    history = [types.Content(role="user", parts=[types.Part(text=full_prompt)])]

    # Init Logger
    logger = GeminiDebugLogger()
    logger.log_api_call("user", full_prompt)

    print("Geminiì—ê²Œ ìš”ì²­ì„ ë³´ë‚´ëŠ” ì¤‘(KIPRIS + Google Search)...")
    
    try:
        # Initial call
        response = client.models.generate_content(
            model="gemini-3-flash-preview", 
            contents=history,
            config=config
        )
        
        # Log first model response
        res_text = response.text if response.candidates[0].content.parts and any(p.text for p in response.candidates[0].content.parts) else "[Tool Call Only]"
        logger.log_api_call("model", res_text, 
                           function_calls=[p.function_call for p in response.candidates[0].content.parts if p.function_call])

        max_turns = 10
        turn_count = 0
        total_usage = response.usage_metadata
        current_response = response

        while turn_count < max_turns and current_response.candidates[0].content.parts and any(p.function_call for p in current_response.candidates[0].content.parts):
            turn_count += 1
            # Add model's response to history
            history.append(current_response.candidates[0].content)
            
            tool_parts = []
            for part in current_response.candidates[0].content.parts:
                if part.function_call:
                    name = part.function_call.name
                    args = part.function_call.args
                    
                    # 1. Skip non-MCP tools (like google_search)
                    # These are handled by Gemini and should not be passed to the MCP connector.
                    if name == "google_search":
                        print(f"ë¡œê·¸: ë‚´ì¥ ë„êµ¬ ë°œê²¬(ìŠ¤í‚µ) - {name}")
                        continue

                    print(f"ë¡œê·¸: MCP ë„êµ¬ í˜¸ì¶œ ì¤‘ - {name}({args})")
                    
                    # 2. Execute MCP tool
                    try:
                        result = await connector.call_tool(name, args)
                        content_text = "\n".join([c.text for c in result.content if hasattr(c, 'text')]) if hasattr(result, 'content') else str(result)
                        logger.log_tool_result(name, content_text)
                        tool_parts.append(types.Part.from_function_response(name=name, response={"result": content_text}))
                    except Exception as e:
                        print(f"ë„êµ¬ í˜¸ì¶œ ì˜¤ë¥˜ ({name}): {e}")
                        tool_parts.append(types.Part.from_function_response(name=name, response={"error": str(e)}))
            
            if tool_parts:
                history.append(types.Content(role="tool", parts=tool_parts))
                current_response = client.models.generate_content(
                    model="gemini-3-flash-preview",
                    contents=history,
                    config=config
                )
                
                if current_response.usage_metadata:
                    total_usage.prompt_token_count += current_response.usage_metadata.prompt_token_count
                    total_usage.candidates_token_count += current_response.usage_metadata.candidates_token_count
                    total_usage.total_token_count += current_response.usage_metadata.total_token_count

                inner_text = current_response.text if current_response.candidates[0].content.parts and any(p.text for p in current_response.candidates[0].content.parts) else "[Tool Call Only]"
                logger.log_api_call("model", inner_text,
                                   function_calls=[p.function_call for p in current_response.candidates[0].content.parts if p.function_call])
            else:
                # If tool_parts is empty (e.g., only google_search was called), 
                # we break the loop to avoid an empty request.
                break
        
        if turn_count >= max_turns:
            print(f"ê²½ê³ : ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜({max_turns})ì— ë„ë‹¬í•˜ì—¬ ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")

        final_text = current_response.text if current_response.candidates[0].content.parts and any(p.text for p in current_response.candidates[0].content.parts) else "ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        print("\n[ìµœì¢… ë¶„ì„ ê²°ê³¼]\n")
        
        if USE_JSON_OUTPUT:
            try:
                # Pretty print JSON
                json_data = json.loads(final_text)
                print(json.dumps(json_data, indent=2, ensure_ascii=False))
            except json.JSONDecodeError:
                print("JSON íŒŒì‹± ì‹¤íŒ¨:")
                print(final_text)
        else:
            print(final_text)
            
        print("\n" + "="*50 + "\n")

        # Citation handling
        text_with_citations = add_citations(current_response)
        
        # Finalize Usage and Log
        logger.set_usage(total_usage)
        debug_path = logger.save()
        print(f"\n[Debug] ìƒì„¸ API í˜¸ì¶œ íë¦„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {debug_path}")

        save_response_to_file(total_usage, PROMPT_1, text_with_citations)

        return final_text
    finally:
        await connector.disconnect()
        print("ë¡œê·¸: MCP ì»¤ë„¥í„°ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


def add_citations(response):
    text = response.text
    if not response.candidates[0].grounding_metadata:
        return text
    
    metadata = response.candidates[0].grounding_metadata
    if not hasattr(metadata, 'grounding_supports') or not metadata.grounding_supports:
        return text

    supports = metadata.grounding_supports
    chunks = metadata.grounding_chunks

    sorted_supports = sorted(supports, key=lambda s: s.segment.end_index, reverse=True)

    for support in sorted_supports:
        end_index = support.segment.end_index
        if support.grounding_chunk_indices:
            citation_links = []
            for i in support.grounding_chunk_indices:
                if i < len(chunks):
                    uri = chunks[i].web.uri
                    citation_links.append(f"[{i + 1}]({uri})")
            citation_string = ", ".join(citation_links)
            text = text[:end_index] + " " + citation_string + text[end_index:]

    return text

def save_response_to_file(token_usage, prompt_text, response_text, folder_path="responses"):
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
    existing_files = os.listdir(folder_path)
    file_count = len(existing_files)
    new_file_name = f"{file_count + 1}.md"
    new_file_path = os.path.join(folder_path, new_file_name)
    text = f"TokensUsage:\n{token_usage}\n\nPrompt:\n{prompt_text}\n\nResponse:\n{response_text}"
    with open(new_file_path, "w", encoding="utf-8") as file:
        file.write(text)
    print(f"Response saved to {new_file_path}")

if __name__ == "__main__":
    print("Start main")
    asyncio.run(main("", SCRIPT))